{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Do a little scraping or API-calling of your own.  Pick a new website and see what you can get out of it.  Expect that you'll run into bugs and blind alleys, and rely on your mentor to help you get through.  \n",
    "\n",
    "Formally, your goal is to write a scraper that will:\n",
    "\n",
    "1) Return specific pieces of information (rather than just downloading a whole page)  \n",
    "2) Iterate over multiple pages/queries  \n",
    "3) Save the data to your computer  \n",
    "\n",
    "Once you have your data, compute some statistical summaries and/or visualizations that give you some new insights into your scraping topic of interest.  Write up a report from scraping code to summary and share it with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This scraper will get prices of cars posted on Craigslist Washington DC**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "class CLSpider(scrapy.Spider):\n",
    "    name = \"CL\"\n",
    "    \n",
    "    allowed_domains = ['https://washingtondc.craigslist.org/']\n",
    "    # Here is where we insert our API call.\n",
    "    start_urls = [\n",
    "        'https://washingtondc.craigslist.org/d/cars-trucks/search/cta'\n",
    "        ]\n",
    "    # Use XPath to parse the response we get.\n",
    "    def parse(self, response):\n",
    "        \n",
    "        # Iterate over every <article> element on the page.\n",
    "        for posting in response.xpath('//p'):\n",
    "            \n",
    "            # Yield a dictionary with the values we want.\n",
    "            yield {\n",
    "                # This is the code to choose what we want to extract\n",
    "                # You can modify this with other Xpath expressions to extract other information from the site\n",
    "                # https://www.w3schools.com/xml/xpath_intro.asp\n",
    "                'title': posting.xpath('a[@class=\"result-title hdrlnk\"]/text()').extract_first(),\n",
    "                'date': posting.xpath('time[@class=\"result-date\"]/text()').extract_first(),\n",
    "                'price': posting.xpath('span/span[@class=\"result-price\"]/text()').extract_first()\n",
    "            }\n",
    "        \n",
    "        # scrape all pages\n",
    "        next_page_relative_url = response.xpath('//a[@class=\"button next\"]/@href').extract_first()\n",
    "        next_page_absolute_url = response.urljoin(next_page_relative_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Tell the script how to run the crawler by passing in settings.\n",
    "process = CrawlerProcess({\n",
    "    'FEED_FORMAT': 'json',         # Store data in JSON format.\n",
    "    'FEED_URI': 'cars.json',  # Name our storage file.\n",
    "    'ROBOTSTXT_OBEY': True,\n",
    "    'USER_AGENT': 'ThinkfulDataScienceBootcamp_Rodolfo (thinkful.com)',\n",
    "    'AUTOTHROTTLE_ENABLED': True,\n",
    "    'HTTPCACHE_ENABLED': True,\n",
    "    'LOG_ENABLED': False           # Turn off logging for now.\n",
    "    # We use CLOSESPIDER_PAGECOUNT to limit our scraper to the first 100 links\n",
    "    #'CLOSESPIDER_PAGECOUNT' : 10\n",
    "})\n",
    "\n",
    "# Start the crawler with our spider.\n",
    "process.crawl(CLSpider)\n",
    "process.start()\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nov  7</td>\n",
       "      <td>$12995</td>\n",
       "      <td>2004 Chevrolet Silverado 2500HD 4dr Crew Cab L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov  7</td>\n",
       "      <td>$6495</td>\n",
       "      <td>2012 VW Jetta 2.5 SE 5 SPEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nov  7</td>\n",
       "      <td>$2950</td>\n",
       "      <td>2004 Hyundai Santa Fe LX, AWD, whith Leather.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov  7</td>\n",
       "      <td>$3500</td>\n",
       "      <td>2002 Honda Odyssey EX-L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nov  7</td>\n",
       "      <td>$5442</td>\n",
       "      <td>2011 Dodge Avenger!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date   price                                              title\n",
       "0  Nov  7  $12995  2004 Chevrolet Silverado 2500HD 4dr Crew Cab L...\n",
       "1  Nov  7   $6495                       2012 VW Jetta 2.5 SE 5 SPEED\n",
       "2  Nov  7   $2950      2004 Hyundai Santa Fe LX, AWD, whith Leather.\n",
       "3  Nov  7   $3500                            2002 Honda Odyssey EX-L\n",
       "4  Nov  7   $5442                              2011 Dodge Avenger!!!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Turning JSON into Data Frame\n",
    "cars = pd.read_json('cars.json')\n",
    "print(cars.shape)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be further processed using the methods we've coverd previously which we'll skip here to save time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
